{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4db56675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for the training set is 33.33333333333333 %\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [126]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m640\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m8\u001b[39m)                                                        \u001b[38;5;66;03m# desired length of use for each image\u001b[39;00m\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m training(folderTraining,width,length)                      \u001b[38;5;66;03m# call to the training function and returns Logistic regression model with the inputted training data set\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mtesting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolderTesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [124]\u001b[0m, in \u001b[0;36mtesting\u001b[1;34m(path, model, width, length)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtesting\u001b[39m(path, model, width , length):                                                           \u001b[38;5;66;03m#method heading testing, takes in the parameters of folder pathway, width and length of the image, and the LogisticRegression model from the training dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m         imgData_test, class_label_test \u001b[38;5;241m=\u001b[39m getData(path,width,length) \n\u001b[0;32m      3\u001b[0m                                \u001b[38;5;66;03m#Recieve Image Data and class label as matrix of the testing dataset from getData()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m         class_label_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(imgData_test)                                               \u001b[38;5;66;03m#List of predicted values from the input from testing data\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#all the imports for project stage \n",
    "from skimage.morphology import convex_hull_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image,ImageFilter,ImageEnhance\n",
    "from numpy import asarray\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import os, os.path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import feature\n",
    "\n",
    "\n",
    "folderTraining= r\"C:\\Users\\andy\\Downloads\\Lego_dataset_2\\Lego_dataset_2\\training\"   # folder pathway for the training data\n",
    "folderTesting= r\"C:\\Users\\andy\\Downloads\\Lego_dataset_2\\Lego_dataset_2\\testing\"     # folder pathway for the testing data\n",
    "width = int(480/8)\n",
    "length = int(640/8)                                                        # desired length of use for each image\n",
    "model = training(folderTraining,width,length)                      # call to the training function and returns Logistic regression model with the inputted training data set\n",
    "testing(folderTesting,model,width,length)                          # call to the testing fucntions which returns the confustion matrix for the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bccb6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(path,width,length):                                                                                          #method heading training, takes in the parameters of folder pathway, width and length of the image\n",
    "    images = []\n",
    "    edges = []\n",
    "    y_edge_train = []\n",
    "    pi = math.pi\n",
    "    directory = os.listdir(training)\n",
    "    def edgeDetection(image):\n",
    "        edges = cv2.Canny(image,0,200)\n",
    "        return [image,edges]\n",
    "    def verticalize_img(img):\n",
    "      # Get the coordinates of the points of interest:\n",
    "        X = np.array(np.where(img > 0)).T\n",
    "                                 # Perform a PCA and compute the angle of the first principal axes\n",
    "        pca = PCA(n_components=2).fit(X)\n",
    "        angle = np.arctan2(*pca.components_[0])\n",
    "        # Rotate the image by the computed angle:\n",
    "        rotated_img = rotate(img,angle/pi*180-90)\n",
    "        return rotated_img \n",
    "    \n",
    "    for i in range(len(directory)):\n",
    "        path = training + 'cir_' + str(i+1) + '.png'\n",
    "        if os.path.exists(path) == 1:\n",
    "            image = cv2.imread(path,0)[0:908,0:908]\n",
    "     #image_size = image.size\n",
    "     #print(image_size)\n",
    "            rotated_image = verticalize_img(image)\n",
    "     #plt.imshow(rotated_image,cmap='gray')\n",
    "     #plt.show()\n",
    " \n",
    "             normalized_image = rotated_image[0:908,0:908]\n",
    " #plt.imshow(normalized_image,cmap='gray')\n",
    " #plt.show()\n",
    " \n",
    "             images.append(edgeDetection(normalized_image)[0])\n",
    "             edges.append(edgeDetection(normalized_image)[1])\n",
    "             y_edge_train.append(0)\n",
    " \n",
    "    for i in range(len(directory)):\n",
    "        path = training + 'rec_' + str(i+1) + '.png'\n",
    "        if os.path.exists(path) == 1:\n",
    "            image = cv2.imread(path,0)[0:908,0:908]\n",
    "                 #image_size = image.size\n",
    "                 #print(image_size)\n",
    "            rotated_image = verticalize_img(image)\n",
    "                 #plt.imshow(rotated_image,cmap='gray')\n",
    "                 #plt.show()\n",
    "\n",
    "            normalized_image = rotated_image[0:908,0:908]\n",
    "                 #plt.imshow(normalized_image,cmap='gray')\n",
    "                 #plt.show()\n",
    "\n",
    "            images.append(edgeDetection(normalized_image)[0])\n",
    "            edges.append(edgeDetection(normalized_image)[1])\n",
    "            y_edge_train.append(1)\n",
    " \n",
    "    for i in range(len(directory)):\n",
    "         path = training + 'squ_' + str(i+1) + '.png'\n",
    "        if os.path.exists(path) == 1:\n",
    "            image = cv2.imread(path,0)[0:908,0:908]\n",
    "             #image_size = image.size\n",
    "             #print(image_size)\n",
    "            rotated_image = verticalize_img(image)\n",
    "             #plt.imshow(rotated_image,cmap='gray')\n",
    "             #plt.show()\n",
    "\n",
    "            normalized_image = rotated_image[0:908,0:908]\n",
    "             #plt.imshow(normalized_image,cmap='gray')\n",
    "             #plt.show()\n",
    "\n",
    "            images.append(edgeDetection(normalized_image)[0])\n",
    "            edges.append(edgeDetection(normalized_image)[1])\n",
    "            y_edge_train.append(2)\n",
    "            y_edge_train = np.array(y_edge_train)\n",
    "            y_edge_train.reshape(-1,1)\n",
    "            \n",
    "print('y_edge_train length = ')\n",
    "print(len(y_edge_train))\n",
    "print('y_edge_train = ')\n",
    "print(y_edge_train)\n",
    "#print(edges)\n",
    "histograms_all = []\n",
    "for count,value in enumerate(edges):\n",
    "     image_pixels = np.array(value)\n",
    "     width = len(image_pixels)\n",
    " #this is a long loop. print(count) is there so we know it isn't frozen\n",
    " print(count)\n",
    " histogram_single_image = []\n",
    " for i in range(width):\n",
    " histogram_single_image.append(0)\n",
    " for j,row in enumerate(image_pixels):\n",
    " for i in row:\n",
    " if(i.any()):\n",
    " histogram_single_image[j] = histogram_single_image[j] + 1\n",
    " histogram_single_image = np.asarray(histogram_single_image)\n",
    " histograms_all.append(histogram_single_image)\n",
    " #if (count > 2):\n",
    " #break\n",
    "histograms_all = np.asarray(histograms_all)\n",
    "#np.concatenate(histograms_all, axis=0 )\n",
    "np.vstack(histograms_all)\n",
    "print('histograms_all length = ')\n",
    "print(len(histograms_all))\n",
    "print('histograms_all = ')\n",
    "print(histograms_all)\n",
    "edge_model = LogisticRegression(max_iter = 1000)\n",
    "edge_model.fit(histograms_all,y_edge_train)\n",
    "edge_pred = edge_model.predict(histograms_all)\n",
    "print('Accuracy Score of the training folder: ')\n",
    "print(accuracy_score(y_edge_train,edge_pred))\n",
    "print('Confusion Matrix of the training folder')\n",
    "print(confusion_matrix(y_edge_train,edge_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "38e1de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(path, model, width , length):                                                           #method heading testing, takes in the parameters of folder pathway, width and length of the image, and the LogisticRegression model from the training dataset\n",
    "        imgData_test, class_label_test = getData(path,width,length) \n",
    "                               #Recieve Image Data and class label as matrix of the testing dataset from getData()\n",
    "        class_label_pred = model.predict(imgData_test)                                               #List of predicted values from the input from testing data\n",
    "        acc_score = accuracy_score(class_label_test,class_label_pred) * 100                         #Calculate the accuracy score from the given testing data set\n",
    "        print(f'The accuracy score for the testing set is {acc_score} %')                           #print the accuracy score\n",
    "        conf_matrix = confusion_matrix(class_label_test,class_label_pred)                           #calculate the confustion matrix from the test class labels to the predicted class labels\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=model.classes_)   #display the confustion matrix as an formatted image with true label vertically and the predicated label horizontally\n",
    "        disp.plot()                                                                                 #plot the confusion matrix\n",
    "        disp.ax_.set_title('Testing Data Confusion Matrix')                                         # set the title for the confusion matrix                                                                           \n",
    "        return accuracy_score, confusion_matrix                                                     # return the value for the accuracy score and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ba3827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_array,edge_thresh,peak_thresh,width,length):\n",
    "    im_width = width\n",
    "    im_length = length\n",
    "    # increase contrast by making image occupy the whole grayscale 0 to 255\n",
    "    image_array = (image_array-np.min(image_array))*255/(np.max(image_array)-np.min(image_array))\n",
    "    # find edges using edge filter\n",
    "    im = Image.fromarray(image_array.reshape(im_width,im_length)).convert('L')\n",
    "      \n",
    "    edges_image = im.filter(ImageFilter.FIND_EDGES)\n",
    "    edges_array = np.asarray(edges_image)\n",
    "    # edge filter produces artificial edges at the boundary, we remove them next\n",
    "    edges_array_scaled = edges_array.copy()[1:im_width-1,1:im_length-1]\n",
    "    # threshold edges to keep only prominent ones\n",
    "    edges_array_scaled[edges_array_scaled < edge_thresh,] = 0 \n",
    "   \n",
    "    # engineer features\n",
    "    edges_v = np.sum(edges_array_scaled,axis=0).astype(float)\n",
    "    edges_h = np.sum(edges_array_scaled,axis=1).astype(float)\n",
    "    # high pass filter, to remove mean from edge features \n",
    "    #(we are interested in fast variations only)\n",
    "    # we do this by subtracting the mean in windows of length M\n",
    "    M = 5\n",
    "    for i in range(len(edges_v)-M):\n",
    "        edges_v[i] = edges_v[i]-np.mean(edges_v[i:i+M])\n",
    "        edges_v[-M:]=0\n",
    "    for i in range(len(edges_h)-M):\n",
    "        edges_h[i] = edges_h[i]-np.mean(edges_h[i:i+M])\n",
    "        edges_h[-M:]=0\n",
    "    # find peak and noise standard deviation in horizontal and vertical edge vectors\n",
    "    peak_v = np.max(np.abs(edges_v))\n",
    "    peak_h = np.max(np.abs(edges_h))\n",
    "    noise_v = edges_v.copy()[np.abs(edges_v) < peak_thresh*peak_v]\n",
    "    noise_h = edges_h.copy()[np.abs(edges_h) < peak_thresh*peak_h]    \n",
    "    sd_v = np.sqrt(np.var(noise_v))\n",
    "    sd_h = np.sqrt(np.var(noise_h))\n",
    "    x = np.array([peak_v/sd_v,peak_h/sd_h]).reshape(1,-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fbfa8229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder,im_width,im_length,label): #function call to put image data and class in x\n",
    "                                              #and y respectively. Folder is the path to the training data, im_width is the \n",
    "                                              #width used to resize the image, im_length is the length used to resize the image\n",
    "                                              #label is the class of the image, n_samples is where we want to stop reading the \n",
    "                                              #data in the folder, start_samples is where we want to start reading the data in\n",
    "                                              #the folder. \n",
    "                        \n",
    "    file_names = os.listdir(folder)           #create an array of all of the file names within the path folder\n",
    "\n",
    "    for i in range(start_samples,n_samples): #creates a for loop that runs while i is in range between start and n_samples\n",
    "        path1 = folder + '/' +file_names[i]        #path1 is the path that shows the path to each individual file within the range\n",
    "        im=Image.open(path1).convert('L')     #creates a variable im, that holds a grayscale image \n",
    "        im1 = ImageEnhance.Sharpness(im)      #Defines the image transformation for altering image sharpness         \n",
    "        im1 = im1.enhance(20)                 #Sharpens the image by a factor of 20\n",
    "        im1 = ImageEnhance.Contrast(im1)      #Defines the image transformation for altering image contrast\n",
    "        im1 = im1.enhance(0.865)              #Decreases the Contrast by a factor of 0.865\n",
    "        im1 = ImageEnhance.Brightness(im1)    #Defines the image transformation for altering image brightness\n",
    "        im1 = im1.enhance(1.25)               #Brightens the image by a factor of 1.25\n",
    "        im1 = im1.resize((im_width,im_length))#Resizes the image to 64x64\n",
    "        image = ndi.rotate(im1, 1,reshape=False, mode='constant') #continuously rotate the previous image by 1 degree without reshaping it\n",
    "        image = ndi.gaussian_filter(image, 1.75) #Applies a gaussian filter to the image. The order is 1.75\n",
    "        edges2 = feature.canny(image, sigma=1.25)#Applies the canny edge detector. Sigma (Standard Deviation of Filter = 1.25)\n",
    "        im = Image.fromarray(edges2.reshape(im_width,im_length)).convert('L') #converts image data back into an image\n",
    "        width, length = im.size                #retrieve the dimensions of that image mentioned\n",
    "        left = width/10\n",
    "        top = length/10\n",
    "        right = width*0.9\n",
    "        bottom = length *0.9\n",
    "        im1=im.crop((left,top,right,bottom))   #crops the image by factors/variables determined above\n",
    "        im1 = im1.resize((im_width,im_length))#Resizes the cropped image to 64x64\n",
    "        im_array = asarray(im1)               #converts image data to array\n",
    "        chull = convex_hull_image(im_array)   #Fills in detected border with white space\n",
    "        edges2 = feature.canny(chull, sigma=1.25) #Applies the canny edge detector. Sigma (Standard Deviation of Filter = 1.25)\n",
    "        n_white_pix = np.sum(chull == True) #Counts how many white pixels exist in the filled in border\n",
    "        x1[i,0]= n_white_pix #Stores pixel count into training matrix\n",
    "      #  im_array = asarray(chull)  \n",
    "      #  x[i,:] = im_array.reshape(1,-1)\n",
    "      #  y[i,0] = classes[label]\n",
    "    return x,y,x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b733adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                    \n",
    "def getData(dataFolder,width, length):                #method heading getData, takes in the parameters of folder pathway, width and length of the image\n",
    "    data_path= os.listdir(dataFolder)                 #list of the file names in the folder of interest such as training and testing                       \n",
    "    imgData= np.empty((len(data_path),width*length))\n",
    "    x1 = np.empty(len(imgData)).reshape(-1,1)                     #creates an empty array of features for the image Data\n",
    "    class_label = np.empty((len(data_path),1))        #creates an empty array of labels for the image Data                \n",
    "    for i in range (len(data_path)):                  #a loop that iterates through the items in the folder of interest and appends a reshaped data array to the image data, which will be used as the X_train, X_test              \n",
    "        pathway = dataFolder + '/' + data_path[i]     #creates a string for the pathway for each image    \n",
    "        image = Image.open(pathway).convert('L')      #Uses the library Image to instantiate the image and converts it to greyscale\n",
    "        image= image.resize((width,length)) \n",
    "        image = ImageEnhance.Contrast(image).enhance(3.6).convert('L')\n",
    "        image = ImageEnhance.Brightness(image).enhance(4.42)\n",
    "        image = ndi.rotate(image, 1, reshape = False, mode = 'constant')                                              # resizes the image to the width and length of users choice          \n",
    "        image = asarray(image)                        #Converts the image to an array of data values           \n",
    "        imgData[i,:] = image.reshape(1,-1)            # Converts and reshapes features of the image data to 1D array    \n",
    "        chull = convex_hull_image(image) #Fills in detected border with white space \n",
    "        edges2 = feature.canny (chull, sigma=1.25) #Applies the canny edge detector. \n",
    "        n_white_pix=np.sum(chull==True) #Counts how many white pixels exist in the \n",
    "        x1[i,0]= n_white_pix #Stores pixel count into training matrix \n",
    "        \n",
    "        \n",
    "        #Since labels are in string value, we need to change it to a int value to name the labels\n",
    "        # 0  means Circle\n",
    "        # 1 means Rectangle\n",
    "        # 2 means Square\n",
    "        if 'cir' in data_path[i]:\n",
    "              class_label[i,0] = 0\n",
    "        if 'rec' in data_path[i]:\n",
    "              class_label[i,0] = 1\n",
    "        if 'squ' in data_path[i]:\n",
    "              class_label[i,0] = 2\n",
    "    return imgData,class_label,x1                        #returns value for the reshaped image data and the integer converted class label describing each lego brick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1b20e51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4730.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_train(folder,im_width,im_length,label,n_samples,start_samples): #function call to put image data and class in x\n",
    "                                              #and y respectively. Folder is the path to the training data, im_width is the \n",
    "                                              #width used to resize the image, im_length is the length used to resize the image\n",
    "                                              #label is the class of the image, n_samples is where we want to stop reading the \n",
    "                                              #data in the folder, start_samples is where we want to start reading the data in\n",
    "                                              #the folder. \n",
    "                        \n",
    "    file_names = os.listdir(folder)           #create an array of all of the file names within the path folder\n",
    "\n",
    "    for i in range(start_samples,n_samples): #creates a for loop that runs while i is in range between start and n_samples\n",
    "        path1 = folder + file_names[i]        #path1 is the path that shows the path to each individual file within the range\n",
    "        im=Image.open(path1).convert('L')     #creates a variable im, that holds a grayscale image \n",
    "        im1 = ImageEnhance.Sharpness(im)      #Defines the image transformation for altering image sharpness         \n",
    "        im1 = im1.enhance(20)                 #Sharpens the image by a factor of 20\n",
    "        im1 = ImageEnhance.Contrast(im1)      #Defines the image transformation for altering image contrast\n",
    "        im1 = im1.enhance(0.865)              #Decreases the Contrast by a factor of 0.865\n",
    "        im1 = ImageEnhance.Brightness(im1)    #Defines the image transformation for altering image brightness\n",
    "        im1 = im1.enhance(1.25)               #Brightens the image by a factor of 1.25\n",
    "        im1 = im1.resize((im_width,im_length))#Resizes the image to 64x64\n",
    "        image = ndi.rotate(im1, 1,reshape=False, mode='constant') #continuously rotate the previous image by 1 degree without reshaping it\n",
    "        image = ndi.gaussian_filter(image, 1.75) #Applies a gaussian filter to the image. The order is 1.75\n",
    "        edges2 = feature.canny(image, sigma=1.25)#Applies the canny edge detector. Sigma (Standard Deviation of Filter = 1.25)\n",
    "        im = Image.fromarray(edges2.reshape(im_width,im_length)).convert('L') #converts image data back into an image\n",
    "        width, length = im.size                #retrieve the dimensions of that image mentioned\n",
    "        left = width/10\n",
    "        top = length/10\n",
    "        right = width*0.9\n",
    "        bottom = length *0.9\n",
    "        im1=im.crop((left,top,right,bottom))   #crops the image by factors/variables determined above\n",
    "        im1 = im1.resize((im_width,im_length))#Resizes the cropped image to 64x64\n",
    "        im_array = asarray(im1)               #converts image data to array\n",
    "        chull = convex_hull_image(im_array)   #Fills in detected border with white space\n",
    "        edges2 = feature.canny(chull, sigma=1.25) #Applies the canny edge detector. Sigma (Standard Deviation of Filter = 1.25)\n",
    "        n_white_pix = np.sum(chull == True) #Counts how many white pixels exist in the filled in border\n",
    "        x1[i,0]= n_white_pix #Stores pixel count into training matrix\n",
    "      #  im_array = asarray(chull)  \n",
    "      #  x[i,:] = im_array.reshape(1,-1)\n",
    "      #  y[i,0] = classes[label]\n",
    "    return x,y,x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce70ab63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3737.],\n",
       "       [3904.],\n",
       "       [3735.],\n",
       "       [3985.],\n",
       "       [3617.],\n",
       "       [4002.],\n",
       "       [3634.],\n",
       "       [4023.],\n",
       "       [3656.],\n",
       "       [3820.],\n",
       "       [3750.],\n",
       "       [4085.],\n",
       "       [3859.],\n",
       "       [4023.],\n",
       "       [3667.],\n",
       "       [3642.],\n",
       "       [3575.],\n",
       "       [4004.],\n",
       "       [3698.],\n",
       "       [3994.],\n",
       "       [3712.],\n",
       "       [3760.],\n",
       "       [3706.],\n",
       "       [4152.],\n",
       "       [3771.],\n",
       "       [3928.],\n",
       "       [3703.],\n",
       "       [4059.],\n",
       "       [3678.],\n",
       "       [3816.],\n",
       "       [3650.],\n",
       "       [3943.],\n",
       "       [3691.],\n",
       "       [3978.],\n",
       "       [3769.],\n",
       "       [4176.],\n",
       "       [3906.],\n",
       "       [4090.],\n",
       "       [3936.],\n",
       "       [3989.],\n",
       "       [3856.],\n",
       "       [3979.],\n",
       "       [4183.],\n",
       "       [3632.],\n",
       "       [3991.],\n",
       "       [3589.],\n",
       "       [3826.],\n",
       "       [3421.],\n",
       "       [4254.],\n",
       "       [3697.],\n",
       "       [4155.],\n",
       "       [4026.],\n",
       "       [3896.],\n",
       "       [3781.],\n",
       "       [4118.],\n",
       "       [3698.],\n",
       "       [3872.],\n",
       "       [3812.],\n",
       "       [3992.],\n",
       "       [3726.],\n",
       "       [3974.],\n",
       "       [3792.],\n",
       "       [4142.],\n",
       "       [4127.],\n",
       "       [4103.],\n",
       "       [3957.],\n",
       "       [3911.],\n",
       "       [3984.],\n",
       "       [3898.],\n",
       "       [4249.],\n",
       "       [3795.],\n",
       "       [3984.],\n",
       "       [3759.],\n",
       "       [3642.],\n",
       "       [3835.],\n",
       "       [3528.],\n",
       "       [3581.],\n",
       "       [3964.],\n",
       "       [3824.],\n",
       "       [3649.],\n",
       "       [3659.],\n",
       "       [3937.],\n",
       "       [2470.],\n",
       "       [3870.],\n",
       "       [3800.],\n",
       "       [3752.],\n",
       "       [3654.],\n",
       "       [3860.],\n",
       "       [3624.],\n",
       "       [3994.],\n",
       "       [3747.],\n",
       "       [3885.],\n",
       "       [3646.],\n",
       "       [3736.],\n",
       "       [3627.],\n",
       "       [3752.],\n",
       "       [3589.],\n",
       "       [3612.],\n",
       "       [3742.],\n",
       "       [3701.],\n",
       "       [3796.],\n",
       "       [3816.],\n",
       "       [3697.],\n",
       "       [3817.],\n",
       "       [3735.],\n",
       "       [4170.],\n",
       "       [3670.],\n",
       "       [3794.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im=Image.open(path1).convert('L')     #creates a variable im, that holds a grayscale image \n",
    "        im1 = ImageEnhance.Sharpness(im)      #Defines the image transformation for altering image sharpness         \n",
    "        im1 = im1.enhance(20)                 #Sharpens the image by a factor of 20\n",
    "        im1 = ImageEnhance.Contrast(im1)      #Defines the image transformation for altering image contrast\n",
    "        im1 = im1.enhance(0.865)              #Decreases the Contrast by a factor of 0.865\n",
    "        im1 = ImageEnhance.Brightness(im1)    #Defines the image transformation for altering image brightness\n",
    "        im1 = im1.enhance(1.25)               #Brightens the image by a factor of 1.25\n",
    "        im1 = im1.resize((width,length))#Resizes the image to 64x64\n",
    "        image = ndi.rotate(im1, 1,reshape=False, mode='constant') #continuously rotate the previous image by 1 degree without reshaping it\n",
    "        image = ndi.gaussian_filter(image, 1.75) #Applies a gaussian filter to the image. The order is 1.75\n",
    "        edges2 = feature.canny(image, sigma=1.25)#Applies the canny edge detector. Sigma (Standard Deviation of Filter = 1.25)\n",
    "        im = Image.fromarray(edges2.reshape(width,length)).convert('L') #converts image data back into an image\n",
    "        width, length = im.size                #retrieve the dimensions of that image mentioned\n",
    "        left = width/10\n",
    "        top = length/10\n",
    "        right = width*0.9\n",
    "        bottom = length *0.9\n",
    "        im1=im.crop((left,top,right,bottom))   #crops the image by factors/variables determined above\n",
    "        im1 = im1.resize((width,length))#Resizes the cropped image to 64x64\n",
    "        im_array = asarray(im1)               #converts image data to array\n",
    "        chull = convex_hull_image(im_array)   #Fills in detected border with white space\n",
    "        edges2 = feature.canny(chull, sigma=1.25) #Applies the canny edge detector. Sigma (Standard Deviation of Filter = 1.25)\n",
    "        n_white_pix = np.sum(chull == True) #Counts how many white pixels exist in the filled in border\n",
    "        x1[i,0]= n_white_pix #Stores pixel count into training matrix\n",
    "         left = width/10\n",
    "        top = length/10\n",
    "        right = width*0.9\n",
    "        bottom = length *0.9\n",
    "        im1=im.crop((left,top,right,bottom))   #crops the image by factors/variables determined above\n",
    "        im1 = im1.resize((width,length))#Resizes the cropped image to 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d47e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_train = len(imgData_train[:,0])\n",
    "    ET = 64\n",
    "    PT = 0.5\n",
    "    edge_features_train = np.empty((P_train,2))\n",
    "                               \n",
    "    for i in range(P_train):\n",
    "        edge_features_train[i,:] = process_image(edge[i,:],ET,PT,width,length)  #ravels the class_label_train input as a 1-D array, containing the elements of the input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
